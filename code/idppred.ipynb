{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation of IDPpred\n",
    "IDPpred method uses three classifiers for predicting intrinsically disordered proteins (IDPs) from protein sequences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sequences(file_path, idp_file_path, output_file_path):\n",
    "    protein_data = []\n",
    "\n",
    "    idp_proteins = []\n",
    "    with open(idp_file_path, 'r') as file:\n",
    "        idp_proteins = {prot_id.strip() for prot_id in file}\n",
    "\n",
    "    with open(file_path, 'r') as file:\n",
    "        for i, line in enumerate(file):\n",
    "            if i >= 5570:\n",
    "                break\n",
    "            parts = line.split()\n",
    "            protein_id = parts[0]\n",
    "            sequence = ''.join(parts[2:])\n",
    "            protein_class = \"idp\" if protein_id in idp_proteins else \"non-idp\"\n",
    "            protein_data.append({\n",
    "                'id': protein_id,\n",
    "                'sequence': sequence.replace('*', ''),\n",
    "                'class': protein_class\n",
    "            })\n",
    "\n",
    "    idp_n = idp_file_path.split('_')[-1].split('.')[0]\n",
    "    idp_n_control = sum(1 for prot_id in protein_data if prot_id['class'] == 'idp')\n",
    "    print(f'Expected: {idp_n}, Found: {idp_n_control}')\n",
    "\n",
    "    with open(output_file_path, 'w') as file:\n",
    "        json.dump(protein_data, file, indent=4)\n",
    "\n",
    "    return protein_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected: 194, Found: 194\n"
     ]
    }
   ],
   "source": [
    "yeast_proteins = load_sequences('data/yeast_sequences.txt', 'data/disprot_yeast_194.txt', 'data/yeast_proteins.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequence based feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ProtIDR based feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "def protseq_to_binseq(protein_sequence):\n",
    "    protein_sequence = list(protein_sequence)\n",
    "    DPaa = ['A', 'R', 'G', 'Q', 'S', 'P', 'E', 'K']\n",
    "    OPaa = ['N', 'W', 'C', 'I', 'F', 'Y', 'V', 'L', 'M', 'D', 'H', 'T']\n",
    "\n",
    "    for i, residue in enumerate(protein_sequence):\n",
    "        if residue in DPaa:\n",
    "            protein_sequence[i] = 1\n",
    "        elif residue in OPaa:\n",
    "            protein_sequence[i] = 0\n",
    "\n",
    "    return protein_sequence\n",
    "\n",
    "\n",
    "def get_protidr_vector(protein_sequence):\n",
    "    # step 1 - protein sequence to binary sequence\n",
    "    binary_sequence = protseq_to_binseq(protein_sequence)\n",
    "\n",
    "    # step 2 - iad vector construction\n",
    "    iad1_vector = []\n",
    "    iad0_vector = []\n",
    "    current_iad1 = 0\n",
    "    found_one = False\n",
    "\n",
    "    current_iad0 = 0\n",
    "    found_zero = False\n",
    "\n",
    "    for i in binary_sequence:\n",
    "        if i == 1:\n",
    "            if found_one: \n",
    "                iad1_vector.append(current_iad1)\n",
    "            current_iad1 = 0\n",
    "            found_one = True\n",
    "        else:\n",
    "            current_iad1 += 1\n",
    "    \n",
    "        if i == 0:\n",
    "            if found_zero: \n",
    "                iad0_vector.append(current_iad0)\n",
    "            current_iad0 = 0\n",
    "            found_zero = True\n",
    "        else:\n",
    "            current_iad0 += 1\n",
    "    \n",
    "    # step 2.1 and 2.2: frequency histograms\n",
    "    iad1_hist, _ = np.histogram(iad1_vector, bins=5, range=(0, 14))\n",
    "    iad0_hist, _ = np.histogram(iad0_vector, bins=5, range=(0, 14))\n",
    "\n",
    "    # Step 2.3: frequency histograms to probability distributions\n",
    "    iad1_probs = iad1_hist / len(iad1_vector) * 100\n",
    "    iad0_probs = iad0_hist / len(iad0_vector) * 100\n",
    "\n",
    "    # ProtIDR vector\n",
    "    protidr_vector = np.append(iad0_probs, iad1_probs)\n",
    "\n",
    "    return protidr_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ProtPCV2 based feature extraction\n",
    "\n",
    "ProtPCV2 vector is constructed following steps mentioned in the paper [ProtPCV](https://link.springer.com/article/10.1007/s12539-020-00380-w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "def protseq_to_binseq2(protein_sequence, pcp):\n",
    "    protein_sequence = list(protein_sequence)\n",
    "    HC_a = ['F','W','Y','H']\n",
    "    HC_ap = ['A','M','C','L','V','I','D','E','N','Q','S','T','R','K','P','G']\n",
    "\n",
    "    PO_p = ['D','E','H','K','N','Q','R','S','T','Y']\n",
    "    PO_np = ['A','C','F','G','I','L','M','P','W','V']\n",
    "    \n",
    "    CC_nz = ['C','I','D','E','N','Q','Y','S','T','R','K','H','P','W','G'] \n",
    "    CC_z = ['A','F','L','M','V']\n",
    "    \n",
    "    HI_hb = ['A','M','C','F','L','V','I']\n",
    "    HI_hp = ['D','E','N','Q','Y','S','T','R','K','H','P','W','G']\n",
    "    \n",
    "    HY_po = ['A','C','F','G','I','P','W','S','T','L','V']\n",
    "    HY_ne = ['D','E','Q','Y','R','K','H','M','N']\n",
    "\n",
    "    for i, residue in enumerate(protein_sequence):\n",
    "        if pcp == \"HC\":\n",
    "            if residue in HC_a:\n",
    "                protein_sequence[i] = 1\n",
    "            elif residue in HC_ap:\n",
    "                protein_sequence[i] = 0\n",
    "        elif pcp == \"PO\":\n",
    "            if residue in PO_p:\n",
    "                protein_sequence[i] = 1\n",
    "            elif residue in PO_np:\n",
    "                protein_sequence[i] = 0\n",
    "        elif pcp == \"CC\":\n",
    "            if residue in CC_nz:\n",
    "                protein_sequence[i] = 1\n",
    "            elif residue in CC_z:\n",
    "                protein_sequence[i] = 0\n",
    "        elif pcp == \"HI\":\n",
    "            if residue in HI_hb:\n",
    "                protein_sequence[i] = 1\n",
    "            elif residue in HI_hp:\n",
    "                protein_sequence[i] = 0\n",
    "        elif pcp == \"HY\":\n",
    "            if residue in HY_po:\n",
    "                protein_sequence[i] = 1\n",
    "            elif residue in HY_ne:\n",
    "                protein_sequence[i] = 0\n",
    "\n",
    "    return protein_sequence\n",
    "\n",
    "\n",
    "def get_protpcv2_vector(protein_sequence):\n",
    "    pcp_list = [\"HC\", \"PO\", \"CC\", \"HI\", \"HY\"]\n",
    "    pcp_list = [\"PO\", \"HC\", \"HI\", \"CC\", \"HY\"]\n",
    "    protpcv2 = []\n",
    "\n",
    "    for pcp in pcp_list:\n",
    "        # step 1 - protein sequence to binary sequence\n",
    "        binary_sequence = protseq_to_binseq2(protein_sequence, pcp)\n",
    "\n",
    "        # step 2 - iad vector construction\n",
    "        iad1_vector = []\n",
    "        iad0_vector = []\n",
    "        current_iad1 = 0\n",
    "        found_one = False\n",
    "\n",
    "        current_iad0 = 0\n",
    "        found_zero = False\n",
    "\n",
    "        for i in binary_sequence:\n",
    "            if i == 1:\n",
    "                if found_one: \n",
    "                    iad1_vector.append(current_iad1)\n",
    "                current_iad1 = 0\n",
    "                found_one = True\n",
    "            else:\n",
    "                current_iad1 += 1\n",
    "        \n",
    "            if i == 0:\n",
    "                if found_zero: \n",
    "                    iad0_vector.append(current_iad0)\n",
    "                current_iad0 = 0\n",
    "                found_zero = True\n",
    "            else:\n",
    "                current_iad0 += 1\n",
    "        \n",
    "        # step 2.1 and 2.2: frequency histograms\n",
    "        iad1_hist, _ = np.histogram(iad1_vector, bins=5, range=(0, 14))\n",
    "        iad0_hist, _ = np.histogram(iad0_vector, bins=5, range=(0, 14))\n",
    "        \n",
    "\n",
    "        # Step 2.3: frequency histograms to probability distributions\n",
    "        iad1_probs = np.where(iad1_hist == 0, 0, iad1_hist / len(iad1_vector)) * 100\n",
    "        iad0_probs = np.where(iad0_hist == 0, 0, iad0_hist / len(iad0_vector)) * 100\n",
    "        # iad1_probs = iad1_hist / len(iad1_vector) * 100\n",
    "        # iad0_probs = iad0_hist / len(iad0_vector) * 100\n",
    "\n",
    "        # ProtIDR vector\n",
    "        protpcv2.append(np.append(iad1_probs, iad0_probs))\n",
    "        \n",
    "    protpcv2 = np.concatenate(protpcv2)\n",
    "    return protpcv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CIDER based feature extraction\n",
    "\n",
    "10 parameters:\n",
    "- fraction of negative charge\n",
    "- fraction of positive charge from Das-Pappu phase diagram\n",
    "- fraction of charged residues\n",
    "- net charge per residue\n",
    "- kappa\n",
    "- omega\n",
    "- sigma\n",
    "- delta\n",
    "- max delta\n",
    "- hydropathy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "from localcider.sequenceParameters import SequenceParameters\n",
    "\n",
    "def get_cider_vector(protein_sequence):\n",
    "    seq = SequenceParameters(protein_sequence)\n",
    "\n",
    "    cider_vector = np.array([\n",
    "        seq.get_fraction_negative(),\n",
    "        seq.get_fraction_positive(),\n",
    "        seq.get_FCR(),\n",
    "        seq.get_NCPR(),\n",
    "        seq.get_kappa(),\n",
    "        seq.get_Omega(),\n",
    "        # sigma (σ) = (f+-f-)2/(f++f-) \n",
    "        (seq.get_fraction_positive() - seq.get_fraction_negative())**2 / (seq.get_fraction_positive() + seq.get_fraction_negative()),\n",
    "        seq.get_delta(),\n",
    "        seq.get_deltaMax(),\n",
    "        seq.get_mean_hydropathy(),\n",
    "    ])\n",
    "\n",
    "    return cider_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Design and implementation of IDPpred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IDPClassifier:\n",
    "    def __init__(self, input_dim, hidden_layers, output_dim=2, activation='relu', lr=0.001, loss=tf.keras.losses.SparseCategoricalCrossentropy()):\n",
    "        self.model = tf.keras.Sequential()\n",
    "\n",
    "        self.model.add(Dense(input_dim, activation=activation, input_shape=(input_dim,)))  # input layer\n",
    "        \n",
    "        for num_neurons in hidden_layers:\n",
    "            self.model.add(Dense(num_neurons, activation=activation))  # hidden layers\n",
    "        self.model.add(Dense(output_dim, activation='sigmoid'))  # output layer\n",
    "\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "        self.model.compile(loss=loss, optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "    def train(self, X_train, y_train, epochs=100, batch_size=32, class_weight=None):\n",
    "        self.model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, class_weight=class_weight)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.model.predict(X)\n",
    "\n",
    "    def save(self, path):\n",
    "        self.model.save_weights(path)\n",
    "\n",
    "    def load(self, path):\n",
    "        self.model.load_weights(path)\n",
    "\n",
    "    def evaluate(self, X_test, y_test):\n",
    "        return self.model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "for protein in yeast_proteins:\n",
    "    X.append(protein['sequence'])\n",
    "    y.append(1 if protein['class'] == 'idp' else 0)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = class_weight.compute_class_weight(\n",
    "    'balanced',\n",
    "    classes=np.unique(y_train),\n",
    "    y=y_train\n",
    ")\n",
    "\n",
    "class_weights = dict(enumerate(class_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 4456\n",
      "test: 1114\n",
      "idp in train: 155\n",
      "idp in test: 39\n"
     ]
    }
   ],
   "source": [
    "print(f'train: {len(X_train)}')\n",
    "print(f'test: {len(X_test)}')\n",
    "\n",
    "print(f'idp in train: {sum(y_train)}')\n",
    "print(f'idp in test: {sum(y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [\"protpcv2\", \"protidr\"]\n",
    "#classifiers = [\"cider\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "protpcv2_classifier = IDPClassifier(input_dim=50, hidden_layers=[40, 20, 10, 5], lr=1e-3)\n",
    "protidr_classifier = IDPClassifier(input_dim=10, hidden_layers=[20, 10], lr=1e-3)\n",
    "cider_classifier = IDPClassifier(input_dim=10, hidden_layers=[20, 10], lr=1e-3)\n",
    "\n",
    "for classifier in classifiers:\n",
    "    if classifier == \"protpcv2\":\n",
    "        X_train_transformed = np.vstack([get_protpcv2_vector(protein) for protein in X_train])\n",
    "        X_test_transformed = np.vstack([get_protpcv2_vector(protein) for protein in X_test])\n",
    "    elif classifier == \"protidr\":\n",
    "        X_train_transformed =  np.vstack([get_protidr_vector(protein) for protein in X_train])\n",
    "        X_test_transformed =  np.vstack([get_protidr_vector(protein) for protein in X_test])\n",
    "    elif classifier == \"cider\":\n",
    "        X_train_transformed = np.vstack([get_cider_vector(protein) for protein in X_train])\n",
    "        X_test_transformed = np.vstack([get_cider_vector(protein) for protein in X_test])\n",
    "    \n",
    "    if classifier == \"protpcv2\":\n",
    "        epochs = 600\n",
    "        print(\"Training protpcv2 classifier\")\n",
    "        protpcv2_classifier.train(X_train_transformed, np.array(y_train), epochs=epochs, batch_size=128, class_weight=class_weights)\n",
    "        protpcv2_classifier.save(f\"./models/{classifier}_classifier_{epochs}_v2.weights.h5\")\n",
    "        print(\"test loss, test acc:\", protpcv2_classifier.evaluate(X_test_transformed, np.array(y_test)))\n",
    "    elif classifier == \"protidr\":\n",
    "        epochs = 300\n",
    "        print(\"Training protidr classifier\")\n",
    "        protidr_classifier.train(X_train_transformed, np.array(y_train), epochs=epochs, batch_size=128, class_weight=class_weights)\n",
    "        protidr_classifier.save(f\"./models/{classifier}_classifier_{epochs}_v2.weights.h5\")\n",
    "        print(\"test loss, test acc:\", protidr_classifier.evaluate(X_test_transformed, np.array(y_test)))\n",
    "    elif classifier == \"cider\":\n",
    "        epochs = 50\n",
    "        print(\"Training cider classifier\")\n",
    "        cider_classifier.train(X_train_transformed,  np.array(y_train), epochs=epochs, batch_size=128, class_weight=class_weights)\n",
    "        cider_classifier.save(f\"./models/{classifier}_classifier_{epochs}.weights.h5\")\n",
    "        print(\"test loss, test acc:\", cider_classifier.evaluate(X_test_transformed, np.array(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "protpcv2_classifier = IDPClassifier(input_dim=50, hidden_layers=[40, 20, 10, 5])\n",
    "protidr_classifier = IDPClassifier(input_dim=10, hidden_layers=[20, 10])\n",
    "cider_classifier = IDPClassifier(input_dim=10, hidden_layers=[20, 10])\n",
    "\n",
    "protpcv2_classifier.load(\"./models/protpcv2_classifier_600_v2.weights.h5\")\n",
    "protidr_classifier.load(\"./models/protidr_classifier_300_v2.weights.h5\")\n",
    "cider_classifier.load(\"./models/cider_classifier_50.weights.h5\")\n",
    "\n",
    "def idp_pred(protein_sequence):\n",
    "    # feature extraction\n",
    "    protpcv2 = get_protpcv2_vector(protein_sequence)\n",
    "    protidr = get_protidr_vector(protein_sequence)\n",
    "    cider = get_cider_vector(protein_sequence)\n",
    "\n",
    "    # initial prediction\n",
    "    protpcv2_pred = protpcv2_classifier.predict(protpcv2.reshape(1, -1))\n",
    "    protidr_pred = protidr_classifier.predict(protidr.reshape(1, -1))\n",
    "    cider_pred = cider_classifier.predict(cider.reshape(1, -1))\n",
    "    # print(protpcv2_pred, protidr_pred, cider_pred)\n",
    "\n",
    "    protpcv2_pred = 1 if protpcv2_pred[0][1] > protpcv2_pred[0][0] else 0\n",
    "    protidr_pred = 1 if protidr_pred[0][1] > protidr_pred[0][0] else 0\n",
    "    cider_pred = 1 if cider_pred[0][1] > cider_pred[0][0] else 0\n",
    "    # print(protpcv2_pred, protidr_pred, cider_pred)\n",
    "\n",
    "    # voting\n",
    "    final_prod = 1 if protpcv2_pred + protidr_pred + cider_pred >= 2 else 0\n",
    "\n",
    "    return final_prod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_idp = [protein for i, protein in enumerate(X_test) if y_test[i] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_positives = 0\n",
    "\n",
    "for protein in test_idp:\n",
    "    if idp_pred(protein) == 1:\n",
    "        true_positives += 1\n",
    "\n",
    "print(f'TP = {true_positives}; FP = {len(test_idp) - true_positives}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 600, 300, 50 --> TP = 18, FP = 21\n",
    "# 600, 300, 50 (v2) --> TP = 24, FP = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_positives = 0\n",
    "true_negatives = 0\n",
    "false_positives = 0\n",
    "false_negatives = 0\n",
    "\n",
    "# true positive rate, sensitivity\n",
    "def tpr(tp, fn):\n",
    "    return tp / (tp + fn) # true positive / actual positive\n",
    "\n",
    "# true negative rate, specificity\n",
    "def tnr(tn, fp):\n",
    "    return tn / (tn + fp) # true negative / actual negative\n",
    "\n",
    "# balanced accuracy\n",
    "def bac(tpr, tnr):\n",
    "    return (tpr + tnr) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x_test, y_test in zip(X_test, y_test):\n",
    "    pred = idp_pred(x_test)\n",
    "    \n",
    "    if y_test == 1 and pred == 1:\n",
    "        true_positives += 1\n",
    "    elif y_test == 0 and pred == 0:\n",
    "        true_negatives += 1\n",
    "    elif y_test == 0 and pred == 1:\n",
    "        false_positives += 1\n",
    "    elif y_test == 1 and pred == 0:\n",
    "        false_negatives += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 24\n",
      "TN: 589\n",
      "FP: 486\n",
      "FN: 15\n",
      "TPR: 0.6153846153846154\n",
      "TNR: 0.5479069767441861\n",
      "BAC: 0.5816457960644008\n"
     ]
    }
   ],
   "source": [
    "print(\"TP:\", true_positives)\n",
    "print(\"TN:\", true_negatives)\n",
    "print(\"FP:\", false_positives)\n",
    "print(\"FN:\", false_negatives)\n",
    "\n",
    "tpr_val = tpr(true_positives, false_negatives)\n",
    "tnr_val = tnr(true_negatives, false_positives)\n",
    "\n",
    "print(\"TPR:\", tpr_val)\n",
    "print(\"TNR:\", tnr_val)\n",
    "print(\"BAC:\", bac(tpr_val, tnr_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
